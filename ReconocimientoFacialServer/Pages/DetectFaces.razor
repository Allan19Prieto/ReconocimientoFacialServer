@* @page "/detect-faces"

@using Emgu.CV;
@using Emgu.CV.Structure;
@using ReconocimientoFacialServer.Services;
@using SkiaSharp;
@using System.Drawing
@inject FaceRecognizerService FaceRecognizerService;
@inject IJSRuntime JSRuntime;

<h3>Detección y Reconocimiento Facial</h3>

<div>
    <video id="cameraPreview" autoplay style="border: 1px solid black; width: 400px; height: 300px;"></video>
    <canvas id="canvasElement" style="display: none;"></canvas>

    <button @onclick="StartCamera">Iniciar Cámara</button>
    <button @onclick="CapturePhoto">Tomar Foto</button>
</div>

@if (ImagePreview != null)
{
    <h4>Foto Capturada:</h4>
    <img src="@ImagePreview" alt="Foto capturada" style="max-width: 400px;" />
}

@if (LivenessMessage != null)
{
    <h4>Verificación de Vida:</h4>
    <p>@LivenessMessage</p>
}

@if (RecognitionResult != null)
{
    <h4>Resultado del Reconocimiento:</h4>
    <p>@RecognitionResult</p>
}


<div style="position: relative; display: inline-block;">
    <video id="videoElement" autoplay style="border: 1px solid black; width: 320px; height: 240px;"></video>
    <canvas id="canvasElement" style="position: absolute; top: 0; left: 0; pointer-events: none;"></canvas>
</div>
<p>@RecognitionResult</p>

<button @onclick="StartVideo">Iniciar Video</button>
<button @onclick="StopVideo">Detener Video</button>

@code {
    private string? ImagePreview;
    // string? RecognitionResult;
    private string? LivenessMessage;

    private string RecognitionResult = "Esperando...";

    private async Task StartCamera()
    {
        try
        {
            await JSRuntime.InvokeVoidAsync("startCamera", "cameraPreview");
        }
        catch (Exception ex)
        {
            RecognitionResult = $"Error al iniciar la cámara: {ex.Message}";
        }
    }

    private async Task StartVideo()
    {
        await JSRuntime.InvokeVoidAsync("startVideoStream", "videoElement");
        await JSRuntime.InvokeVoidAsync("processVideoFrame", "videoElement", "canvasElement", DotNetObjectReference.Create(this));
    }

    private async Task StopVideo()
    {
        await JSRuntime.InvokeVoidAsync("stopVideoStream", "videoElement");
    }

    private async Task CapturePhoto()
    {
        try
        {
            // Capturar imagen desde la cámara
            var imageBase64 = await JSRuntime.InvokeAsync<string>("captureImage", "cameraPreview", "canvasElement");

            // Verificar autenticidad (Liveness Detection)
            bool isAlive = await FaceRecognizerService.VerifyLivenessAsync(imageBase64);

            if (!isAlive)
            {
                LivenessMessage = "No se detectó vida. Por favor, intente nuevamente.";
                return;
            }

            LivenessMessage = "Verificación de vida exitosa.";

            // Reconocimiento facial
            RecognitionResult = FaceRecognizerService.RecognizeFace(imageBase64);
            ImagePreview = imageBase64;

            // // Convertir Base64 a SKBitmap
            // var skBitmap = FaceRecognizerService.ConvertBase64ToSkBitmap(imageBase64);

            // // Detectar rostros en la imagen capturada
            // var detectedFaces = FaceRecognizerService.DetectFaces(skBitmap);

            // if (detectedFaces.Length > 0)
            // {
            //     // Recortar y redimensionar el primer rostro detectado
            //     //var firstFace = detectedFaces[0];
            //     //var croppedFace = CropFace(skBitmap, new SKRectI(firstFace.X, firstFace.Y, firstFace.Width, firstFace.Height));
            //     //var resizedFace = ResizeBitmap(croppedFace, 100, 100);

            //     var croppedFace = FaceRecognizerService.CropFace(skBitmap, detectedFaces[0]);
            //     var resizedFace = FaceRecognizerService.ResizeBitmap(croppedFace, 100, 100);

            //     // Convertir rostro recortado a Base64
            //     //ImagePreview = ConvertSkBitmapToBase64(resizedFace);
            //     ImagePreview = FaceRecognizerService.ConvertSkBitmapToBase64(resizedFace);

            //     // Realizar reconocimiento facial
            //     RecognitionResult = FaceRecognizerService.RecognizeFace(ImagePreview);
            // }
            // else
            // {
            //     RecognitionResult = "No se detectaron rostros en la imagen.";
            // }
        }
        catch (Exception ex)
        {
            RecognitionResult = $"Error al capturar o procesar la imagen: {ex.Message}";
        }
    }

    private SKBitmap CropFace(SKBitmap bitmap, SKRectI faceRect)
    {
        var croppedBitmap = new SKBitmap(faceRect.Width, faceRect.Height);
        using var canvas = new SKCanvas(croppedBitmap);
        canvas.DrawBitmap(bitmap, faceRect, new SKRect(0, 0, faceRect.Width, faceRect.Height));
        return croppedBitmap;
    }

    private SKBitmap ResizeBitmap(SKBitmap bitmap, int width, int height)
    {
        var resizedBitmap = new SKBitmap(width, height);
        using var canvas = new SKCanvas(resizedBitmap);
        canvas.DrawBitmap(bitmap, new SKRect(0, 0, bitmap.Width, bitmap.Height), new SKRect(0, 0, width, height));
        return resizedBitmap;
    }

    private bool IsBase64String(string base64)
    {
        Span<byte> buffer = new Span<byte>(new byte[base64.Length]);
        return Convert.TryFromBase64String(base64, buffer, out _);
    }

    [JSInvokable]
    public async Task ProcessFrame(string base64Image)
    {
        try
        {
            // Convertir Base64 a Mat para procesar
            var matImage = FaceRecognizerService.ConvertBase64ToSkBitmap(base64Image);

            //var skBitmap = FaceRecognizerService.ConvertBase64ToSkBitmap(imageBase64);

            // Detectar y reconocer rostros
            var detectedFaces = FaceRecognizerService.DetectFaces(matImage);
            if (detectedFaces.Length > 0)
            {
                var croppedFace = FaceRecognizerService.CropFace(matImage, detectedFaces[0]);
                var maptoSk = FaceRecognizerService.ConvertSkBitmapToMat(croppedFace);
                RecognitionResult = FaceRecognizerService.RecognizeFace(FaceRecognizerService.ConvertMatToBase64(maptoSk));
            }
            else
            {
                RecognitionResult = "No se detectaron rostros.";
            }
        }
        catch (Exception ex)
        {
            RecognitionResult = $"Error: {ex.Message}";
        }
    }

    public class Rectangle
    {
        public int X { get; set; }
        public int Y { get; set; }
        public int Width { get; set; }
        public int Height { get; set; }
    }

    [JSInvokable("ProcessFaces")]
    public List<Rectangle> ProcessFaces(string base64Image)
    {
        try
        {
            // Convertir la imagen Base64 a Mat
            var skBitmap = FaceRecognizerService.ConvertBase64ToSkBitmap(base64Image);
            //var matImage = FaceRecognizerService.ConvertSkBitmapToMat(skBitmap);

            // Detectar rostros usando Haar Cascade
            var detectedFaces = FaceRecognizerService.DetectFaces(skBitmap);

            // Convertir Rectangles a un formato serializable
            return detectedFaces.Select(face => new Rectangle
                {
                    X = face.X,
                    Y = face.Y,
                    Width = face.Width,
                    Height = face.Height
                }).ToList();
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error al detectar rostros: {ex.Message}");
            return new List<Rectangle>();
        }
    }

    


}
 *@